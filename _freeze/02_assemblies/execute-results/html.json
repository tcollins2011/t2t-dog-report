{
  "hash": "726f9a3a0e007f786b994fc78be5bd6e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Contig Assemblies (hifiasm)\"\ndescription: \"Contig-level quality across six dogs (primary, hap1, hap2)\"\nformat:\n  html:\n    toc: true\n    code-fold: show\n    df-print: paged\nexecute:\n  echo: true\n  warning: false\n  message: false\n---\n\n## What this chapter shows\n\nWe summarize **contig-level** assemblies produced by **hifiasm** (primary, hap1, hap2). We report N50/L50-style contiguity and total size, then visualize cross-dog differences. N50 is a weighted median contig length such that **50% of the assembly** is in contigs ≥ N50; NG50 is the same concept but uses an **expected genome size** as the denominator (useful for between-assembly comparisons).\n\n> Notes  \n> - Domestic dog (Canis familiaris) nuclear genome is ~**2.4–2.5 Gb**; we use 2.45 Gb as a default expected size for NG-metrics.\n> - hifiasm generates **primary** and **haplotype-resolved** contigs (hap1, hap2) from HiFi data, enabling direct comparison of maternal/paternal assemblies.\n\n::: callout-tip\nWe keep scaffolding (RagTag) and annotation (Liftoff) in later chapters so this section reflects **raw contiguity** from hifiasm.\n:::\n\n## Summary Table\n\nThese come from your linking script (`data/*_{hap1|hap2|primary}.stats.tsv`) and contain: `num`, `sum`, `n50`, `max`, `mean`.\n\n::: {#320bb3b7 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n\nasm = pd.read_csv(\"data/assemblies.tsv\", sep=\"\\t\")\n# Human-friendly labels\nlabel_map = {\"p_ctg\":\"primary\", \"hap1.p_ctg\":\"hap1\", \"hap2.p_ctg\":\"hap2\"}\nasm[\"assembly\"] = asm[\"assembly\"].map(label_map).fillna(asm[\"assembly\"])\n\n# Normalize dog names (lowercase → Title)\nasm[\"dog\"] = asm[\"dog\"].str.title()\n\n# Order columns\nasm = asm[[\"dog\",\"assembly\",\"contigs\",\"length_bp\",\"n50_bp\",\"max_bp\",\"mean_bp\"]]\nasm.sort_values([\"dog\",\"assembly\"], inplace=True)\nasm\n\nasm_summary = (asm\n  .assign(length_Gb=lambda d: d[\"length_bp\"]/1e9,\n          n50_Mb=lambda d: d[\"n50_bp\"]/1e6,\n          max_Mb=lambda d: d[\"max_bp\"]/1e6,\n          mean_kb=lambda d: d[\"mean_bp\"]/1e3)\n  [[\"dog\",\"assembly\",\"contigs\",\"length_Gb\",\"n50_Mb\",\"max_Mb\",\"mean_kb\"]]\n  .rename(columns={\"length_Gb\":\"length (Gb)\",\"n50_Mb\":\"N50 (Mb)\",\"max_Mb\":\"max (Mb)\",\"mean_kb\":\"mean (kb)\"}))\nasm_summary\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dog</th>\n      <th>assembly</th>\n      <th>contigs</th>\n      <th>length (Gb)</th>\n      <th>N50 (Mb)</th>\n      <th>max (Mb)</th>\n      <th>mean (kb)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Appa</td>\n      <td>hap1</td>\n      <td>119</td>\n      <td>2.418026</td>\n      <td>55.151629</td>\n      <td>123.265682</td>\n      <td>20319.5437</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Appa</td>\n      <td>hap2</td>\n      <td>109</td>\n      <td>2.369512</td>\n      <td>54.720232</td>\n      <td>123.504004</td>\n      <td>21738.6466</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Appa</td>\n      <td>primary</td>\n      <td>83</td>\n      <td>2.471283</td>\n      <td>54.723395</td>\n      <td>129.348512</td>\n      <td>29774.4987</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Molly</td>\n      <td>hap1</td>\n      <td>167</td>\n      <td>2.433310</td>\n      <td>53.708796</td>\n      <td>123.888497</td>\n      <td>14570.7164</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Molly</td>\n      <td>hap2</td>\n      <td>140</td>\n      <td>2.454928</td>\n      <td>55.958338</td>\n      <td>123.316267</td>\n      <td>17535.2018</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Molly</td>\n      <td>primary</td>\n      <td>117</td>\n      <td>2.474317</td>\n      <td>63.049053</td>\n      <td>123.888497</td>\n      <td>21148.0099</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Noodle</td>\n      <td>hap1</td>\n      <td>130</td>\n      <td>2.446466</td>\n      <td>57.963758</td>\n      <td>123.335643</td>\n      <td>18818.9729</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Noodle</td>\n      <td>hap2</td>\n      <td>148</td>\n      <td>2.315743</td>\n      <td>57.921322</td>\n      <td>92.319795</td>\n      <td>15646.9100</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Noodle</td>\n      <td>primary</td>\n      <td>97</td>\n      <td>2.469626</td>\n      <td>63.224845</td>\n      <td>123.517932</td>\n      <td>25460.0583</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Orfhlaith</td>\n      <td>hap1</td>\n      <td>137</td>\n      <td>2.443127</td>\n      <td>49.813152</td>\n      <td>89.842402</td>\n      <td>17833.0412</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Orfhlaith</td>\n      <td>hap2</td>\n      <td>133</td>\n      <td>2.448507</td>\n      <td>53.631617</td>\n      <td>123.560014</td>\n      <td>18409.8266</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Orfhlaith</td>\n      <td>primary</td>\n      <td>106</td>\n      <td>2.465162</td>\n      <td>57.955801</td>\n      <td>123.560035</td>\n      <td>23256.2441</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Pandan</td>\n      <td>hap1</td>\n      <td>169</td>\n      <td>2.323921</td>\n      <td>50.290859</td>\n      <td>101.016635</td>\n      <td>13751.0093</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Pandan</td>\n      <td>hap2</td>\n      <td>249</td>\n      <td>2.373947</td>\n      <td>43.148106</td>\n      <td>123.283190</td>\n      <td>9533.9246</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Pandan</td>\n      <td>primary</td>\n      <td>115</td>\n      <td>2.468097</td>\n      <td>54.673020</td>\n      <td>123.283190</td>\n      <td>21461.7101</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Zeke</td>\n      <td>hap1</td>\n      <td>173</td>\n      <td>2.358435</td>\n      <td>53.662931</td>\n      <td>95.335571</td>\n      <td>13632.5699</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Zeke</td>\n      <td>hap2</td>\n      <td>142</td>\n      <td>2.370843</td>\n      <td>57.981274</td>\n      <td>104.955800</td>\n      <td>16696.0788</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Zeke</td>\n      <td>primary</td>\n      <td>98</td>\n      <td>2.471667</td>\n      <td>62.705175</td>\n      <td>126.123749</td>\n      <td>25221.0887</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Headline continuity plots \n\n::: {#1f0bff02 .cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nwanted = [\"primary\",\"hap1\",\"hap2\"]  \n# ---- Bar plot of N50 ----\nfig, ax = plt.subplots(figsize=(8,4))\npivot_n50 = (asm\n    .pivot(index=\"dog\", columns=\"assembly\", values=\"n50_bp\")\n    .reindex(sorted(asm[\"dog\"].unique()))\n    .reindex(columns=wanted) \n)\nx = np.arange(len(pivot_n50))\nw = 0.27\nfor i, col in enumerate(pivot_n50.columns):\n    ax.bar(x + i*w, pivot_n50[col]/1e6, width=w, label=col)\nax.set_xticks(x + w)\nax.set_xticklabels(pivot_n50.index, rotation=0)\nax.set_ylabel(\"N50 (Mb)\")\nax.set_title(\"Contig N50 by dog and haplotype\")\nax.legend()\nplt.tight_layout()\nplt.show()\n\n# ---- Total assembled size vs expected dog genome size ----\nexpected_bp = 2.45e9  # Canis familiaris ~2.4–2.5 Gb\nfig, ax = plt.subplots(figsize=(8,4))\npivot_sum = (asm\n    .pivot(index=\"dog\", columns=\"assembly\", values=\"length_bp\")\n    .reindex(sorted(asm[\"dog\"].unique()))\n    .reindex(columns=wanted)  \n)\nx = np.arange(len(pivot_sum)); w = 0.27\nfor i, col in enumerate(pivot_sum.columns):\n    ax.bar(x + i*w, pivot_sum[col]/1e9, width=w, label=col)\nax.axhline(expected_bp/1e9, linestyle=\"--\")\nax.set_xticks(x + w); ax.set_xticklabels(pivot_sum.index)\nax.set_ylabel(\"Assembly length (Gb)\")\nax.set_title(\"Total contig length vs expected dog genome size (~2.45 Gb)\")\nax.legend()\nplt.tight_layout()\nplt.show()\n\n# ---- Cumulative-length (lens) plots ----\nimport glob, re, math\n\ndef load_lens(path):\n    s = pd.read_csv(path, sep=r\"\\s+\", header=None, names=[\"len\"])\n    s = s.sort_values(\"len\", ascending=False).reset_index(drop=True)\n    s[\"cum\"] = s[\"len\"].cumsum()\n    return s\n\nlens_files = sorted(glob.glob(\"data/*_primary.fa.lens\") + glob.glob(\"data/*_hap1.fa.lens\") + glob.glob(\"data/*_hap2.fa.lens\"))\nif lens_files:\n    ncols = 3\n    nrows = math.ceil(len(lens_files)/ncols)\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 3*nrows), squeeze=False)\n    for ax, f in zip(axes.flatten(), lens_files):\n        m = re.match(r\"data/([a-zA-Z0-9_-]+)_(primary|hap1|hap2)\\.fa\\.lens\", f)\n        if not m:  \n            ax.axis(\"off\"); ax.set_title(f\"Unrecognized: {f}\")\n            continue\n        dog, hap = m.group(1).title(), m.group(2)\n        df = load_lens(f)\n        total = df[\"len\"].sum()\n        ax.plot(range(1, len(df)+1), df[\"cum\"]/1e9)\n        ax.axhline(total*0.5/1e9, linestyle=\"--\")\n        ax.set_title(f\"{dog} {hap}\")\n        ax.set_xlabel(\"# contigs (sorted)\"); ax.set_ylabel(\"Cumulative length (Gb)\")\n    plt.tight_layout(); plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](02_assemblies_files/figure-html/cell-3-output-1.png){width=757 height=373}\n:::\n\n::: {.cell-output .cell-output-display}\n![](02_assemblies_files/figure-html/cell-3-output-2.png){width=757 height=373}\n:::\n\n::: {.cell-output .cell-output-display}\n![](02_assemblies_files/figure-html/cell-3-output-3.png){width=1144 height=1716}\n:::\n:::\n\n\n## Nx curves and area-under-Nx (auN)\n\n::: {#8df2466f .cell execution_count=3}\n``` {.python .cell-code}\n# --- Nx curves split into two panels -------------------------------------\nimport glob, re, pandas as pd, matplotlib.pyplot as plt, numpy as np\n\ndef load_lengths(path):\n    s = pd.read_csv(path, sep=r\"\\s+\", header=None, names=[\"len\"])\n    return s[\"len\"].sort_values(ascending=False).to_numpy()\n\ndef nx_curve(lengths):\n    cs  = lengths.cumsum()\n    tot = cs[-1]\n    nx_vals = [lengths[cs >= tot*(x/100)][0] for x in range(1,101)]\n    return np.arange(1,101), np.array(nx_vals)\n\ndef auN(nx_vals):          # area-under-Nx curve\n    return nx_vals.sum() / 100\n\n# collect curves\nlens_files = sorted(glob.glob(\"data/*_primary.fa.lens\") + glob.glob(\"data/*_hap1.fa.lens\") + glob.glob(\"data/*_hap2.fa.lens\"))\ncurves, summary = [], []\nfor f in lens_files:\n    m = re.match(r\".*/([A-Za-z]+)_(primary|hap1|hap2)\\.fa\\.lens\", f)\n    if not m:\n        continue\n    dog, asm = m.group(1).title(), m.group(2)\n    nx, vals = nx_curve(load_lengths(f))\n    curves.append((dog, asm, nx, vals))\n    summary.append({\"dog\":dog, \"assembly\":asm, \"auN_Mb\":auN(vals)/1e6})\n\nif not curves:\n    raise RuntimeError(\"No *.fa.lens files found; check your symlinks\")\n\n# split dogs 50 / 50\ndogs = sorted({d for d,_,_,_ in curves})\nmid  = len(dogs)//2\ngroups = [set(dogs[:mid]), set(dogs[mid:])]\n\nfor gidx, gset in enumerate(groups, start=1):\n    fig, ax = plt.subplots(figsize=(7,5))\n    for dog, asm, nx, vals in curves:\n        if dog not in gset:          # skip dogs not in this half\n            continue\n        ls = \"-\" if asm==\"primary\" else \"--\" if asm==\"hap1\" else \":\"\n        ax.plot(nx, vals/1e6, ls, label=f\"{dog} {asm}\")\n    ax.set_xlabel(\"x in Nx (%)\")\n    ax.set_ylabel(\"Contig length (Mb)\")\n    ax.set_title(f\"Nx curves — group {gidx} / 2  (higher & right = more contiguous)\")\n    ax.legend(fontsize=8, ncol=2)\n    plt.tight_layout(); plt.show()\n\n# --- auN summary table (unchanged) ---------------------------------------\nauN_df = (pd.DataFrame(summary)\n          .pivot(index=\"dog\", columns=\"assembly\", values=\"auN_Mb\")\n          .reindex(columns=[\"primary\",\"hap1\",\"hap2\"]))\nauN_df.round(1)\n\n```\n\n::: {.cell-output .cell-output-display}\n![](02_assemblies_files/figure-html/cell-4-output-1.png){width=661 height=468}\n:::\n\n::: {.cell-output .cell-output-display}\n![](02_assemblies_files/figure-html/cell-4-output-2.png){width=661 height=468}\n:::\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>assembly</th>\n      <th>primary</th>\n      <th>hap1</th>\n      <th>hap2</th>\n    </tr>\n    <tr>\n      <th>dog</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Appa</th>\n      <td>63.6</td>\n      <td>56.5</td>\n      <td>58.1</td>\n    </tr>\n    <tr>\n      <th>Molly</th>\n      <td>62.1</td>\n      <td>55.7</td>\n      <td>58.1</td>\n    </tr>\n    <tr>\n      <th>Noodle</th>\n      <td>61.8</td>\n      <td>58.0</td>\n      <td>55.1</td>\n    </tr>\n    <tr>\n      <th>Orfhlaith</th>\n      <td>60.5</td>\n      <td>49.2</td>\n      <td>55.3</td>\n    </tr>\n    <tr>\n      <th>Pandan</th>\n      <td>58.3</td>\n      <td>51.7</td>\n      <td>49.4</td>\n    </tr>\n    <tr>\n      <th>Zeke</th>\n      <td>67.1</td>\n      <td>53.0</td>\n      <td>56.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n",
    "supporting": [
      "02_assemblies_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}